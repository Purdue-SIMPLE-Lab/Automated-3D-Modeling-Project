{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "yolo.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "OdAEXE0TFJVQ"
   ],
   "mount_file_id": "1AV4datbS1tLuVfMTeJ8TXZqRa44FMFS2",
   "authorship_tag": "ABX9TyMks2joAuOTlZB3l9rv/YiU"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6-9-VrEe_9b",
    "colab_type": "text"
   },
   "source": [
    " # 挂载谷歌云盘\n",
    " 这一步很重要，Colab的运行原理实际上就是给你分配一台远程的带GPU的主机，所以它的原始路径不是你的谷歌云盘（也就是你的代码文件）所在的路径。所以第一步我们先要把谷歌云盘挂载带到那台远程主机上"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YCnk8-n5ecx2",
    "colab_type": "code",
    "outputId": "1bbe259f-4613-474d-be9f-944765a285b8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1590723684043,
     "user_tz": 240,
     "elapsed": 20788,
     "user": {
      "displayName": "Cheng Peng",
      "photoUrl": "",
      "userId": "07985724713606108822"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    }
   },
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j68Wt_YXfn--",
    "colab_type": "text"
   },
   "source": [
    "# 更改运行目录"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4rCtMRwie8n0",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import os\n",
    "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/Yolo\")"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiRPNzJrjGuc",
    "colab_type": "text"
   },
   "source": [
    "# 安装"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xEnMvbV1jJ0K",
    "colab_type": "code",
    "outputId": "d84a9fc4-53ca-4a97-8766-b2fb12957ef8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1590707489681,
     "user_tz": 240,
     "elapsed": 7517,
     "user": {
      "displayName": "Cheng Peng",
      "photoUrl": "",
      "userId": "07985724713606108822"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    }
   },
   "source": [
    "! git clone https://github.com/YunYang1994/tensorflow-yolov3.git"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Cloning into 'tensorflow-yolov3'...\n",
      "remote: Enumerating objects: 1750, done.\u001B[K\n",
      "remote: Total 1750 (delta 0), reused 0 (delta 0), pack-reused 1750\u001B[K\n",
      "Receiving objects: 100% (1750/1750), 62.86 MiB | 18.20 MiB/s, done.\n",
      "Resolving deltas: 100% (1058/1058), done.\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCIy4HycyNZR",
    "colab_type": "text"
   },
   "source": [
    "不能用pip安装tensorflow，官方提示了会与GPU冲突，尽量使用自带的。 [Avoid Using pip install with GPUs and TPUs](https://colab.research.google.com/notebooks/tensorflow_version.ipynb#scrollTo=8UvRkm1JGUrk)\n",
    "- numpy==1.15.1\n",
    "- Pillow==5.3.0\n",
    "- scipy==1.1.0\n",
    "- ~~tensorflow-gpu==1.11.0~~\n",
    "- wget==3.2\n",
    "- seaborn==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "egmfRddnbE2v",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "! pip install numpy==1.15.1\n",
    "! pip install Pillow==5.3.0\n",
    "! pip install scipy==1.1.0\n",
    "! pip install wget==3.2\n",
    "! pip install seaborn==0.9.0"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CpQ-1t2anUnq",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "% cd tensorflow-yolov3/checkpoint\n",
    "! wget https://github.com/YunYang1994/tensorflow-yolov3/releases/download/v1.0/yolov3_coco.tar.gz\n",
    "! tar -xvf yolov3_coco.tar.gz"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7UvBMf6B18L-",
    "colab_type": "text"
   },
   "source": [
    "# 运行"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "66n4jgv92Nhh",
    "colab_type": "code",
    "outputId": "3d78f78c-797e-40ba-c29f-3a4ead6d528d",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1590723692729,
     "user_tz": 240,
     "elapsed": 1421,
     "user": {
      "displayName": "Cheng Peng",
      "photoUrl": "",
      "userId": "07985724713606108822"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    }
   },
   "source": [
    "%tensorflow_version 1.x"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2zzywI0yzws5",
    "colab_type": "code",
    "outputId": "ea28d5bf-0ed6-4f47-bd08-f52073d3b8d3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1590723698040,
     "user_tz": 240,
     "elapsed": 2403,
     "user": {
      "displayName": "Cheng Peng",
      "photoUrl": "",
      "userId": "07985724713606108822"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    }
   },
   "source": [
    "%cd tensorflow-yolov3\n",
    "%ls"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/Colab Notebooks/Yolo/tensorflow-yolov3\n",
      "\u001B[0m\u001B[01;34mcheckpoint\u001B[0m/        from_darknet_weights_to_ckpt.py  \u001B[01;34mscripts\u001B[0m/\n",
      "convert_weight.py  from_darknet_weights_to_pb.py    \u001B[01;34mtest_material\u001B[0m/\n",
      "\u001B[01;34mcore\u001B[0m/              image_demo.py                    train.py\n",
      "\u001B[01;34mdata\u001B[0m/              LICENSE                          video_demo.py\n",
      "\u001B[01;34mdocs\u001B[0m/              LICENSE.fuck                     yolov3_coco.pb\n",
      "evaluate.py        \u001B[01;34mmAP\u001B[0m/\n",
      "freeze_graph.py    README.md\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oNhMn-DRnn45",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "! python ./convert_weight.py"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bFLRYRL_r7OL",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "! python ./freeze_graph.py"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7eVPBWe426e",
    "colab_type": "text"
   },
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nGql4dQ345GQ",
    "colab_type": "code",
    "outputId": "87167c63-b72f-4fd3-a7c9-f113fd7f97fd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1591379481592,
     "user_tz": 240,
     "elapsed": 2769,
     "user": {
      "displayName": "Cheng Peng",
      "photoUrl": "",
      "userId": "07985724713606108822"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    }
   },
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "import os\n",
    "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/Yolo\")\n",
    "# %tensorflow_version 1.x\n",
    "# %cd tensorflow-yolov3\n",
    "# %ls"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n",
      "/content/gdrive/My Drive/Colab Notebooks/Yolo/tensorflow-yolov3\n",
      "1.png              from_darknet_weights_to_ckpt.py  \u001B[0m\u001B[01;34mmAP\u001B[0m/\n",
      "\u001B[01;34mcheckpoint\u001B[0m/        from_darknet_weights_to_pb.py    README.md\n",
      "convert_weight.py  image_demo.py                    \u001B[01;34mscripts\u001B[0m/\n",
      "\u001B[01;34mcore\u001B[0m/              \u001B[01;34mimage_test_result\u001B[0m/               \u001B[01;34mtest_material\u001B[0m/\n",
      "\u001B[01;34mdata\u001B[0m/              input.mp4                        train.py\n",
      "\u001B[01;34mdocs\u001B[0m/              input.png                        video_demo.py\n",
      "evaluate.py        LICENSE                          yolov3_coco.pb\n",
      "freeze_graph.py    LICENSE.fuck\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OdAEXE0TFJVQ",
    "colab_type": "text"
   },
   "source": [
    "## 输入视频，输出视频+每帧图像"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "z3qkBz2q8Y8H",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import core.utils as utils\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "return_elements = [\"input/input_data:0\", \"pred_sbbox/concat_2:0\", \"pred_mbbox/concat_2:0\", \"pred_lbbox/concat_2:0\"]\n",
    "# 模型pb文件路径\n",
    "pb_file = \"./yolov3_coco.pb\"\n",
    "# 视频图像路径\n",
    "video_path= \"./input.mp4\"\n",
    "# 摄像头输入端\n",
    "# video_path = 0\n",
    "#保存视频路径\n",
    "save_path=\"./result.avi\"\n",
    "#是否保存检测结果视频\n",
    "storable=True\n",
    "# 目标检测类别总数\n",
    "num_classes = 80\n",
    "# 输入图像的尺寸\n",
    "input_size = 416\n",
    "#从video_path中加载视频\n",
    "#若video_path=0加载照相机中视频若video_path=\"str\"加载str路径下的视频\n",
    "vid = cv2.VideoCapture(video_path)\n",
    "#获得fps值\n",
    "fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "#获取vid的每一帧图像大小\n",
    "size = (int(vid.get(cv2.CAP_PROP_FRAME_WIDTH)), int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "#声明保存视频的路径、视频编码格式、fps、图像尺寸大小\n",
    "videoWriter = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc('I', '4', '2', '0'), fps, size)\n",
    "print(111)\n",
    "\n",
    "#tf.graph(),定义计算图\n",
    "# 计算图用于构建网络，本身不进行任何实际的计算\n",
    "graph = tf.Graph()\n",
    "# 从pb文件将计算图导入到当前默认图中\n",
    "return_tensors = utils.read_pb_return_tensors(graph, pb_file, return_elements)\n",
    "with tf.Session(graph=graph) as sess:\n",
    "  while True:\n",
    "    #按帧读取视频,vid.read()返回两个值,\n",
    "    #return是bool值,如果读取帧正确则返回True，如果文件读取到结尾,他的返回值就为False\n",
    "    #fram是三维矩阵，就是每一帧的图像\n",
    "    return_value, frame = vid.read()\n",
    "    if return_value:\n",
    "      #cv2.VideoCapture()读取后的图像为BGR格式\n",
    "      #将每一帧BGR图像转换成RGB图像,便于图像处理\n",
    "      frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "      #array转换成image\n",
    "      image = Image.fromarray(frame)\n",
    "    else:\n",
    "      # raise ValueError(\"No image!\")\n",
    "      break\n",
    "    #获取图像尺寸大小\n",
    "    frame_size = frame.shape[:2]\n",
    "    #图像预处理,这块图像其实没有发生变化\n",
    "    #因为target_size和frame.shape[:2]是一样的\n",
    "    image_data = utils.image_preporcess(np.copy(frame), [input_size, input_size])\n",
    "    #增加一维，就是batch_size维,默认该维度为1\n",
    "    image_data = image_data[np.newaxis, ...]\n",
    "    #获取每一帧处理前的时间戳\n",
    "    prev_time = time.time()\n",
    "    #得到三种bounding box\n",
    "    pred_sbbox, pred_mbbox, pred_lbbox = sess.run(\n",
    "    [return_tensors[1], return_tensors[2], return_tensors[3]],\n",
    "    feed_dict={ return_tensors[0]: image_data})\n",
    "    #将预测结果组成一个矩阵\n",
    "    pred_bbox = np.concatenate([np.reshape(pred_sbbox, (-1, 5 + num_classes)),\n",
    "    np.reshape(pred_mbbox, (-1, 5 + num_classes)),\n",
    "    np.reshape(pred_lbbox, (-1, 5 + num_classes))], axis=0)\n",
    "    #TODO:\n",
    "    bboxes = utils.postprocess_boxes(pred_bbox, frame_size, input_size, 0.3)\n",
    "    #非极大值抑制，IOU的阈值设为0.45\n",
    "    bboxes = utils.nms(bboxes, 0.45, method='nms')\n",
    "    #TODO:\n",
    "    #得到的结果是一张张图片\n",
    "    image = utils.draw_bbox(frame, bboxes)\n",
    "    #获得每一帧处理后的时间戳\n",
    "    curr_time = time.time()\n",
    "    #计算每一帧处理时间\n",
    "    exec_time = curr_time - prev_time\n",
    "    result = np.asarray(image)\n",
    "    # 输出每一帧处理时间\n",
    "    print(\"time: %.2f ms\" %(1000*exec_time))\n",
    "    #图片的标题\n",
    "    # cv2.namedWindow(\"result\", cv2.WINDOW_AUTOSIZE)\n",
    "    #将RGB格式转化为BGR格式，便于cv2显示\n",
    "    # result = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    #显示图像\n",
    "    cv2.imwrite(str(\"./test_result/\"+str(curr_time)+\".jpg\"), result) \n",
    "    # cv2.imshow(\"result\", result)\n",
    "    #保存图像\n",
    "    if storable:\n",
    "      videoWriter.write(result)\n",
    "    #键盘延迟1ms按'q'键退出\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):break\n",
    "print(\"---------------------------------结束---------------------------------------\")"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSCd6FR3FdXK",
    "colab_type": "text"
   },
   "source": [
    "## 输入**图片**， 输出图片"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wLZXAM4lFocj",
    "colab_type": "code",
    "outputId": "8a457ab7-d9ed-447b-b823-b51cd0ef13ef",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1591379543018,
     "user_tz": 240,
     "elapsed": 4203,
     "user": {
      "displayName": "Cheng Peng",
      "photoUrl": "",
      "userId": "07985724713606108822"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    }
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import core.utils as utils\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import time\n",
    "import math\n",
    "\n",
    "def fire_hydrants_classification(self, original_image):\n",
    "\n",
    "    return_elements = [\"input/input_data:0\", \"pred_sbbox/concat_2:0\", \"pred_mbbox/concat_2:0\", \"pred_lbbox/concat_2:0\"]\n",
    "    pb_file         = \"./yolov3_coco.pb\"\n",
    "    image_path      = \"./input.png\"\n",
    "    num_classes     = 80\n",
    "    input_size      = 416\n",
    "    graph           = tf.Graph()\n",
    "\n",
    "    # original_image = cv2.imread(image_path)\n",
    "    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "    original_image_size = original_image.shape[:2]\n",
    "    image_data = utils.image_preporcess(np.copy(original_image), [input_size, input_size])\n",
    "    image_data = image_data[np.newaxis, ...]\n",
    "\n",
    "    return_tensors = utils.read_pb_return_tensors(graph, pb_file, return_elements)\n",
    "\n",
    "\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        pred_sbbox, pred_mbbox, pred_lbbox = sess.run(\n",
    "            [return_tensors[1], return_tensors[2], return_tensors[3]],\n",
    "                    feed_dict={ return_tensors[0]: image_data})\n",
    "\n",
    "    pred_bbox = np.concatenate([np.reshape(pred_sbbox, (-1, 5 + num_classes)),\n",
    "                                np.reshape(pred_mbbox, (-1, 5 + num_classes)),\n",
    "                                np.reshape(pred_lbbox, (-1, 5 + num_classes))], axis=0)\n",
    "\n",
    "    bboxes = utils.postprocess_boxes(pred_bbox, original_image_size, input_size, 0.3)\n",
    "    bboxes = utils.nms(bboxes, 0.45, method='nms')\n",
    "\n",
    "\n",
    "    # 裁剪图像\n",
    "    for i in bboxes:\n",
    "      print(i)\n",
    "      if i[5] == 10.0:\n",
    "        # 向上取整不需要判断是否越界，最大值只会等于shape\n",
    "        # 裁剪坐标为[y0:y1, x0:x1]\n",
    "        cropped_image = original_image[int(i[1]):math.ceil(i[3]),int(i[0]):math.ceil(i[2])]\n",
    "        break\n",
    "\n",
    "\n",
    "    # 转换RGB格式\n",
    "    cropped_image = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB)\n",
    "    return cropped_image\n",
    "    # image = Image.fromarray(image)\n",
    "    # 保存cropped_image图像\n",
    "    # cv2.imwrite(\"./image_test_result/cropped_image.png\", cropped_image)\n",
    "\n",
    "    # 画框框 draw_bbox\n",
    "    image = utils.draw_bbox(original_image, bboxes)\n",
    "    # 转换RGB格式\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # 保存image图像\n",
    "    # cv2.imwrite(\"./image_test_result/full_image.png\", image)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    image_path = \"./input.png\"\n",
    "    original_image = cv2.imread(image_path)\n",
    "    cropped_image = fire_hydrants_classification(original_image)\n",
    "    cv2.imwrite(\"./image_test_result/cropped_image.png\", cropped_image)"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fire_hydrants_classification() missing 1 required positional argument: 'original_image'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-2-033788e2303c>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     66\u001B[0m     \u001B[0mimage_path\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"./input.png\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     67\u001B[0m     \u001B[0moriginal_image\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimage_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 68\u001B[1;33m     \u001B[0mcropped_image\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfire_hydrants_classification\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moriginal_image\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     69\u001B[0m     \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimwrite\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"./image_test_result/cropped_image.png\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcropped_image\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     70\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: fire_hydrants_classification() missing 1 required positional argument: 'original_image'"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 输入视频，cropped图像"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun  8 02:34:45 2020\n",
      "[ 1.59567916  0.         42.44668579 32.86462784  0.84042156  2.        ]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'cropped_image' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnboundLocalError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-5-b2dff3334752>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m()\u001B[0m\n\u001B[0;32m    116\u001B[0m     \u001B[0mprev_time\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    117\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 118\u001B[1;33m     \u001B[0mimage\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfire_hydrants_classification\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    119\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    120\u001B[0m     \u001B[1;31m#获得每一帧处理后的时间戳\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-5-b2dff3334752>\u001B[0m in \u001B[0;36mfire_hydrants_classification\u001B[1;34m(original_image)\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     51\u001B[0m     \u001B[1;31m# 转换RGB格式\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 52\u001B[1;33m     \u001B[0mcropped_image\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcvtColor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcropped_image\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mCOLOR_BGR2RGB\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     53\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mcropped_image\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     54\u001B[0m     \u001B[1;31m# image = Image.fromarray(image)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mUnboundLocalError\u001B[0m: local variable 'cropped_image' referenced before assignment"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import core.utils as utils\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import math\n",
    "\n",
    "def fire_hydrants_classification(original_image):\n",
    "\n",
    "    return_elements = [\"input/input_data:0\", \"pred_sbbox/concat_2:0\", \"pred_mbbox/concat_2:0\", \"pred_lbbox/concat_2:0\"]\n",
    "    pb_file         = \"./yolov3_coco.pb\"\n",
    "    image_path      = \"./input.png\"\n",
    "    num_classes     = 80\n",
    "    input_size      = 416\n",
    "    graph           = tf.Graph()\n",
    "\n",
    "    # original_image = cv2.imread(image_path)\n",
    "    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "    original_image_size = original_image.shape[:2]\n",
    "    image_data = utils.image_preporcess(np.copy(original_image), [input_size, input_size])\n",
    "    image_data = image_data[np.newaxis, ...]\n",
    "\n",
    "    return_tensors = utils.read_pb_return_tensors(graph, pb_file, return_elements)\n",
    "\n",
    "\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        pred_sbbox, pred_mbbox, pred_lbbox = sess.run(\n",
    "            [return_tensors[1], return_tensors[2], return_tensors[3]],\n",
    "                    feed_dict={ return_tensors[0]: image_data})\n",
    "\n",
    "    pred_bbox = np.concatenate([np.reshape(pred_sbbox, (-1, 5 + num_classes)),\n",
    "                                np.reshape(pred_mbbox, (-1, 5 + num_classes)),\n",
    "                                np.reshape(pred_lbbox, (-1, 5 + num_classes))], axis=0)\n",
    "\n",
    "    bboxes = utils.postprocess_boxes(pred_bbox, original_image_size, input_size, 0.3)\n",
    "    bboxes = utils.nms(bboxes, 0.45, method='nms')\n",
    "\n",
    "\n",
    "    # 裁剪图像\n",
    "    for i in bboxes:\n",
    "      print(i)\n",
    "      if i[5] == 10.0:\n",
    "        # 向上取整不需要判断是否越界，最大值只会等于shape\n",
    "        # 裁剪坐标为[y0:y1, x0:x1]\n",
    "        cropped_image = original_image[int(i[1]):math.ceil(i[3]),int(i[0]):math.ceil(i[2])]\n",
    "        break\n",
    "\n",
    "\n",
    "    # 转换RGB格式\n",
    "    cropped_image = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB)\n",
    "    return cropped_image\n",
    "    # image = Image.fromarray(image)\n",
    "    # 保存cropped_image图像\n",
    "    # cv2.imwrite(\"./image_test_result/cropped_image.png\", cropped_image)\n",
    "\n",
    "    # 画框框 draw_bbox\n",
    "    image = utils.draw_bbox(original_image, bboxes)\n",
    "    # 转换RGB格式\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # 保存image图像\n",
    "    # cv2.imwrite(\"./image_test_result/full_image.png\", image)\n",
    "\n",
    "\n",
    "\n",
    "return_elements = [\"input/input_data:0\", \"pred_sbbox/concat_2:0\", \"pred_mbbox/concat_2:0\", \"pred_lbbox/concat_2:0\"]\n",
    "# 模型pb文件路径\n",
    "pb_file = \"./yolov3_coco.pb\"\n",
    "# 视频图像路径\n",
    "video_path= \"./input.mp4\"\n",
    "# 摄像头输入端\n",
    "# video_path = 0\n",
    "#保存视频路径\n",
    "save_path=\"./result.avi\"\n",
    "#是否保存检测结果视频\n",
    "storable=True\n",
    "# 目标检测类别总数\n",
    "num_classes = 80\n",
    "# 输入图像的尺寸\n",
    "input_size = 416\n",
    "#从video_path中加载视频\n",
    "#若video_path=0加载照相机中视频若video_path=\"str\"加载str路径下的视频\n",
    "vid = cv2.VideoCapture(video_path)\n",
    "#获得fps值\n",
    "fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "#获取vid的每一帧图像大小\n",
    "size = (int(vid.get(cv2.CAP_PROP_FRAME_WIDTH)), int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "#声明保存视频的路径、视频编码格式、fps、图像尺寸大小\n",
    "videoWriter = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc('I', '4', '2', '0'), fps, size)\n",
    "print(time.asctime( time.localtime(time.time())))\n",
    "\n",
    "count = 0\n",
    "\n",
    "#tf.graph(),定义计算图\n",
    "# 计算图用于构建网络，本身不进行任何实际的计算\n",
    "graph = tf.Graph()\n",
    "# 从pb文件将计算图导入到当前默认图中\n",
    "return_tensors = utils.read_pb_return_tensors(graph, pb_file, return_elements)\n",
    "with tf.Session(graph=graph) as sess:\n",
    "  while True:\n",
    "    #按帧读取视频,vid.read()返回两个值,\n",
    "    #return是bool值,如果读取帧正确则返回True，如果文件读取到结尾,他的返回值就为False\n",
    "    #fram是三维矩阵，就是每一帧的图像\n",
    "    return_value, frame = vid.read()\n",
    "    if return_value:\n",
    "      #cv2.VideoCapture()读取后的图像为BGR格式\n",
    "      #将每一帧BGR图像转换成RGB图像,便于图像处理\n",
    "      frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "      #array转换成image\n",
    "      # image = Image.fromarray(frame)\n",
    "    else:\n",
    "      # raise ValueError(\"No image!\")\n",
    "      break\n",
    "    #获取每一帧处理前的时间戳\n",
    "    prev_time = time.time()\n",
    "\n",
    "    image = fire_hydrants_classification(frame)\n",
    "\n",
    "    #获得每一帧处理后的时间戳\n",
    "    curr_time = time.time()\n",
    "    #计算每一帧处理时间\n",
    "    exec_time = curr_time - prev_time\n",
    "    result = np.asarray(image)\n",
    "    # 输出每一帧处理时间\n",
    "    print(\"time: %.2f ms\" %(1000*exec_time))\n",
    "    #图片的标题\n",
    "    # cv2.namedWindow(\"result\", cv2.WINDOW_AUTOSIZE)\n",
    "    #将RGB格式转化为BGR格式，便于cv2显示\n",
    "    # result = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    #显示图像\n",
    "    count += 1\n",
    "    cv2.imwrite(str(\"./image_test_result/\"+str(count)+\".jpg\"), result)\n",
    "    # cv2.imshow(\"result\", result)\n",
    "    #保存图像\n",
    "    # if storable:\n",
    "    #   videoWriter.write(result)\n",
    "    #键盘延迟1ms按'q'键退出\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):break\n",
    "print(\"---------------------------------结束---------------------------------------\")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}